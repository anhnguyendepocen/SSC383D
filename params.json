{"name":"SSC 383D","tagline":"Statistical Modeling II","body":"### Details\r\n* Instructor: James Scott (firstname dot lastname at mccombs dot utexas dot edu)\r\n* Meeting time: Mondays and Wednesdays, 11:00 to 12:30, in FAC 101B.\r\n* Syllabus: [here](https://github.com/jgscott/SSC383D/blob/master/syllabus/syllabus-2013-SSC383D.pdf?raw=true)\r\n\r\n### Course Description\r\nSSC 383D is a capstone graduate-level course on multivariate statistical modeling.  It is intended for Ph.D students in statistics, but also suitable for graduate students in other disciplines with (1) substantial previous statistical training, and (2) an interest in designing bespoke statistical methods for their own data sets.\r\n\r\nWe will focus on statistical inference arising from formal probability models.  The course is taught primarily, although not exclusively, from a Bayesian perspective.  Major topics to be covered include: theory of the multivariate normal distribution; mixture models and other latent-variable models; density estimation; hierarchical models; generalized linear models; and ``non-iid'' models incorporating, for example, spatial or temporal dependence.  Examples will be taken from across the social, biological, and physical sciences.\r\n\r\n\r\n### Week by week\r\n[Exercises 1.](https://github.com/jgscott/SSC383D/blob/master/Chapter01/exercises01-SSC384D.pdf?raw=true)  These problems focus on simple conjugate families; the multivariate normal distribution; and some basic theory on multiple regression and the quantification of uncertainty from a frequentist perspective. I expect this to take us through the first two weeks of class. Further files can be found in the Chapter01/references/ and Chapter01/examples/ directories on GitHub.\r\n\r\n[Exercises 2:](https://github.com/jgscott/SSC383D/blob/master/Chapter02/exercises02-SSC384D.pdf?raw=true) Introduction to smoothing.\r\n\r\n[Exercises 3:](https://github.com/jgscott/SSC383D/blob/master/Chapter03/exercises03-SSC384D.pdf?raw=true) Gaussian processes; smoothing from a Bayesian perspective.\r\n\r\n[Exercises 4:](https://github.com/jgscott/SSC383D/blob/master/Chapter04/exercises04-SSC383D.pdf?raw=true) Backfitting and Gibbs sampling.\r\n\r\n[Exercises 5:](https://github.com/jgscott/SSC383D/blob/master/Chapter05/exercises05-SSC383D.pdf?raw=true) Hierarchy, shrinkage, and data augmentation.\r\n\r\n[Exercises 6:](https://github.com/jgscott/SSC383D/blob/master/Chapter06/exercises06-SSC383D.pdf?raw=true) Mixture models.\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}